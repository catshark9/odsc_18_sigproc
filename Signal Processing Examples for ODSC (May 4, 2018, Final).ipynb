{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal Processing Examples for ODSC (May 4, 2018)\n",
    "===\n",
    "\n",
    "This notebook contains several examples that accompany the talk *Making the Most of Your Time Series:  Signal \n",
    "Processing for Machine Learning Applications*, presented at ODSC East 2018.  Information on the build that's being used to run this notebook:\n",
    "\n",
    "* Python 2.7 \n",
    "* *pandas* 0.18.1\n",
    "* *numpy* 1.11.0\n",
    "* *scipy* 0.17.1\n",
    "* *matplotlib* 1.5.1\n",
    "* (optional) *folium* 0.5.0\n",
    "\n",
    "I don't expect newer distributions of any of these packages to pose problems, but no guarantees.  \n",
    "\n",
    "Table of Contents\n",
    "--\n",
    "* <a href=#import_load>Import Basic Packages and Load Data </a>\n",
    "* <a href=#win_med_mean>Windowed Mean and Median Filtering</a> \n",
    "* <a href=#fft_stuff>The Fast Fourier Transform (FFT)</a>\n",
    "* <a href=#butter>Butterworth Filtering </a>\n",
    "\n",
    "NOTE\n",
    "--\n",
    "I'm using my *nav_fusion* kernel right now to load various sensorplay files, but once I find the data I want, I'm just going to pickle it and load that in.\n",
    "\n",
    "<a id=import_load></a>\n",
    "Import Basic Packages and Load Data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib notebook\n",
    "\n",
    "#CHANGE PATH BELOW TO LOCAL PATH ON YOUR OWN DEVICE!\n",
    "accel=pd.read_csv('data/accel.csv',index_col=0)\n",
    "accel_raw=pd.read_csv('data/accel_raw.csv',index_col=0) \n",
    "gyro=pd.read_csv('data/gyro.csv',index_col=0)     \n",
    "gps=pd.read_csv('data/gps.csv',index_col=0)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=win_med_mean></a>\n",
    "Windowed Mean and Median Filtering\n",
    "===\n",
    "\n",
    "To illustrate windowed mean and median filtering, we're going to look at some GPS data for a phone that travelled in a car for approximately 20 minutes.  *gps* is a pandas DataFrame that records several GPS-related quantities in one second intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a whole lot going on during the first 10 seconds (speed is 0!).  If we plot the longitude vs. the latitude, \n",
    "we can trace out the path taken by the car:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNCOMMENT THE CODE BELOW IF YOU HAVE FOLIUM INSTALLED:\n",
    "\n",
    "# import folium\n",
    "# from IPython.core.display import display\n",
    "# map1 = folium.Map(location=[42.417631,-71.075679], zoom_start=14, width=\"100%\", height=\"100%\")\n",
    "# for ii in range(len(gps)):\n",
    "#     folium.CircleMarker(location=[gps.lat.iloc[ii], gps.lon.iloc[ii]],\n",
    "#                         radius=3).add_to(map1)\n",
    "# display(map1)\n",
    "\n",
    "pl.figure(figsize=(8,8))\n",
    "pl.plot(gps.lon,gps.lat)\n",
    "pl.grid()\n",
    "pl.title('Path of Phone')\n",
    "pl.xlabel('Longitude (Deg)')\n",
    "pl.ylabel('Latitude (Deg)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the data as a time series by plotting each individual component of the GPS location---latitude, longitude, and altitude---vs. time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,10))\n",
    "ax1=pl.subplot(311)\n",
    "pl.plot(gps.lat)\n",
    "# pl.title('GPS Latitude')\n",
    "pl.ylabel('Latitude (Deg)')\n",
    "pl.grid()\n",
    "\n",
    "pl.subplot(312,sharex=ax1)\n",
    "pl.plot(gps.lon)\n",
    "# pl.title('GPS Longitude')\n",
    "pl.ylabel('Longitude (Deg)')\n",
    "pl.grid()\n",
    "\n",
    "pl.subplot(313,sharex=ax1)\n",
    "pl.plot(gps.alt)\n",
    "# pl.title('GPS Altitude')\n",
    "pl.ylabel('Altitude (m)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with Rolling Mean/Median Filters on Altitude Data\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"win_size\" is the length of the window over which we compute the mean/median.  Will look at lengths of 5,11, and 101 \n",
    "# for demonstration\n",
    "\n",
    "win_size=5\n",
    "gps_med_filt=gps.alt.rolling(window=win_size,center=True).median()\n",
    "gps_mean_filt=gps.alt.rolling(window=win_size,center=True).mean()\n",
    "\n",
    "pl.figure(figsize=(9,7))\n",
    "line1,=pl.plot(gps.alt,'--r')\n",
    "line2,=pl.plot(gps_med_filt,'b')\n",
    "line3,=pl.plot(gps_mean_filt,'g')\n",
    "pl.legend([line1,line2,line3],['Unfilt. Altitude','Rolling Median','Rolling Mean'],loc=0)\n",
    "pl.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=fft_stuff></a>\n",
    "The Fast Fourier Transform (FFT)\n",
    "===\n",
    "We're first going to start off by computing the FFT of the toy example listed in the slides:\n",
    "$$x(t)=\\cos 2\\pi t + \\frac{1}{2}\\cos 4\\pi t$$.\n",
    "\n",
    "If correctly computed, we should see spikes at 1 Hz and 2 Hz and no energy elsewhere.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time=3\n",
    "dt=0.01\n",
    "t=np.arange(0,end_time,dt)\n",
    "x=np.cos(2*np.pi*t)+0.5*np.cos(4*np.pi*t)\n",
    "X=fft.fft(x)\n",
    "freq=fft.fftfreq(len(t),dt)\n",
    "\n",
    "#FFT is computed for both positive and *negative* frequencies.  For real-valued signals, the value of the FFT at \n",
    "#negative frequencies is the complex conjugate of the corresponding positive frequency value.  An artifact of the way \n",
    "#that the FFT is computed is that the negative frequencies are computed *after* the positive frequencies are.  \n",
    "#The \"fftshift\" command re-orders the data so that negative frequencies occur before positive ones.\n",
    "X=fft.fftshift(X)\n",
    "freq=fft.fftshift(freq)\n",
    "\n",
    "pl.figure(figsize=(12,6))\n",
    "pl.subplot(121)\n",
    "pl.plot(t,x)\n",
    "pl.grid()\n",
    "pl.title('Time Series x(t)')\n",
    "pl.xlabel('time (sec)')\n",
    "\n",
    "\n",
    "pl.subplot(122)\n",
    "\n",
    "#In general, the Fourier transform is a sequence of *complex* numbers.  The magnitude of the Fourier transform provides\n",
    "#an indication of how much energy is present in a signal at different frequencies, so that's what we'll plot here:\n",
    "pl.plot(freq,np.abs(X),'-x')\n",
    "\n",
    "#Only going to look at positive frequencies:\n",
    "pl.xlim((0,freq[-1]))\n",
    "pl.grid()\n",
    "pl.title('Fourier Transform X(f)')\n",
    "pl.xlabel('Frequency (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT of Accelerometer Data\n",
    "--\n",
    "\n",
    "For our next example, we're going to compute the FFT of some accelerometer data, depicted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(9,7))\n",
    "line1,line2,line3,=pl.plot(accel)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Accelerometer Data for Person Leaving Car at Trip End')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken at the end of a road trip.  During the first 10 seconds, the phone is stationary, and the during the next ten seconds, the user leaves the car and starts walking.  The accelerometer is *tri-axial*, meaning that it records acceleration data on a set three orthogonal axes as depicted below:\n",
    "\n",
    "<img src='images/sensors-coordinates2.jpg' width=\"400\">\n",
    "\n",
    "Each of the three axes stores a separate time series.  We'll compute the FFT of just one axis for illustration.  \n",
    "\n",
    "Note that walking motion is periodic in nature (you can see some periodicity in the time series above) and, therefore, we should expect to see some \"spikes\" in the Fourier transform at the users walking frequency and at *harmonics* integer multiples of the walking frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accel=fft.fft(accel.x.values)\n",
    "dt=np.diff(accel.index)[0]\n",
    "f_vec=fft.fftfreq(len(Accel),dt)\n",
    "\n",
    "#Make sure frequencies are in the right order.\n",
    "Accel=fft.fftshift(Accel)\n",
    "f_vec=fft.fftshift(f_vec)\n",
    "\n",
    "pl.figure(figsize=(12,6))\n",
    "ax1=pl.subplot(121)\n",
    "pl.plot(f_vec,np.abs(Accel))\n",
    "pl.xlim((0,f_vec[-1]))\n",
    "pl.grid()\n",
    "pl.title('FFT of Acceleration (Linear y-scale)')\n",
    "pl.xlabel('Frequency (Hz)')\n",
    "pl.subplot(122,sharex=ax1)\n",
    "pl.semilogy(f_vec,np.abs(Accel))\n",
    "pl.xlim((0,f_vec[-1]))\n",
    "pl.grid()\n",
    "pl.title('FFT of Acceleration (Log. y-scale)')\n",
    "pl.xlabel('Frequency (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=butter></a>\n",
    "Butterworth Filtering\n",
    "===\n",
    "For this next part, we're going to examine the *raw* acceleration recorded at the end of the same trip that we examined above.  The data is depicted below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(9,7))\n",
    "line1,line2,line3,=pl.plot(accel_raw)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Raw Accelerometer Data')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the slides, the raw acceleration is the sum of two components:  a *gravity* component and an *phon eacceleration* component:\n",
    "\n",
    "$$a_m = g + a_d$$\n",
    "\n",
    "(There were also a noise and bias component in the original equation, but we're going to assume that those are both negligible for the analysis performed here).\n",
    "\n",
    "We are generally interested in separating out the gravity component from the phone acceleration component.  The phone acceleration provides us information about how the phone/car is behaving at different points of time, while the gravity component provides us with other important auxilliary information (it's a critical piece of information for estimating the orientation of the phone, for instance).  The proper way to separate out these two components is to use a *Kalman Filter*.  This type of filter utilizes information from the both the accelerometer and the gyroscope to estimate the gravity vector accurately.  The mechanics of these types of filters is significantly more complex than what we have time to describe here and, instead, we're going to investigate some approximate methods of quickly separating gravity from phone acceleration.\n",
    "\n",
    "Our approximate way of separating gravity from the phone acceleration data will be to extract an estimate of gravity via a *lowpass* filter and to extract the remaining phone acceleration via a *highpass* filter.  There are a few reasons why a lowpass filter to extract a rough estimate of gravity from human walking activity is a reasonable approximation.  The first is that the gravity vector has significant changes only with significant changes in the orientation of the phone.  Such changes tend to happen infrequently and are, hence, low frequency events.  On the other hand, acceleration profiles for someone moving a phone tend to be \"zero mean\".  If there *were* a component of the acceleration that were constant while the user was walking with the phone, the lowpass filter would erroneously include that in the gravity estimate (indeed, this same technique is NOT a good idea when a car is actively accelerating or braking!).  But people tend to walk at constant speeds which, by definition, have zero net acceleration.  \n",
    "\n",
    "Below, we're going to design lowpass and highpass *Butterworth filters* to extract an estimate of gravity and a \n",
    "separate estimate of phone acceleration.  In the code block below we:\n",
    "1.  Design the filters and plot their weight functions $W(f)$,\n",
    "2.  Apply the filters to the raw accelerometer data to extract our gravity and phone acceleration estimates, and\n",
    "2.  Show how these filters affect the FFT of the raw accelerometer data when applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cutoff=1.25 #frequency (in Hz) where we want our Butterworth Filter to start to transition.\n",
    "f_s=100. #frequency (in Hz) which represents sample rate of data.\n",
    "\n",
    "[b_low,a_low]=signal.filter_design.butter(3,2*f_cutoff/f_s,btype='lowpass')\n",
    "[b_high,a_high]=signal.filter_design.butter(3,2*f_cutoff/f_s,btype='highpass')\n",
    "#NOTE:  in practice don't need to both lowpass *and* highpass filter data, since the highpass-filtered data can be \n",
    "#obtained by subtracting the lowpass-filtered data from the original data.  Creating both filters here for \n",
    "#illustration only.\n",
    "\n",
    "w,h_low=signal.freqz(b_low,a_low)\n",
    "w,h_high=signal.freqz(b_high,a_high)\n",
    "\n",
    "f_vec=w/np.pi*f_s/2.\n",
    "pl.figure(figsize=(12,6))\n",
    "pl.subplot(121)\n",
    "pl.plot(f_vec,np.abs(h_low))\n",
    "pl.ylim((0,1.1))\n",
    "pl.grid()\n",
    "pl.title('Lowpass Filter W(f)')\n",
    "pl.subplot(122)\n",
    "pl.plot(f_vec,np.abs(h_high))\n",
    "pl.grid()\n",
    "pl.ylim((0,1.1))\n",
    "pl.title('Highpass Filter W(f)')\n",
    "\n",
    "#Crude estimate of gravity:\n",
    "grav_est=signal.filtfilt(b_low,a_low,accel_raw.values,axis=0)\n",
    "grav_est=pd.DataFrame(data=grav_est,index=accel_raw.index,columns=['x','y','z'])\n",
    "\n",
    "#Crude estimate of acceleration data\n",
    "accel_est=signal.filtfilt(b_high,a_high,accel_raw.values,axis=0)\n",
    "accel_est=pd.DataFrame(data=accel_est,index=accel_raw.index,columns=['x','y','z'])\n",
    "\n",
    "\n",
    "#Plot Fourier Transforms of Original, Lowpass Filtered, and Highpass filtered data:\n",
    "\n",
    "Accel_raw=fft.fft(accel_raw.x.values)\n",
    "dt=np.diff(accel.index)[0]\n",
    "f_vec=fft.fftfreq(len(Accel_raw),dt)\n",
    "\n",
    "#Make sure frequencies are in the right order.\n",
    "Accel_raw=fft.fftshift(Accel_raw)\n",
    "f_vec=fft.fftshift(f_vec)\n",
    "\n",
    "Grav_est=fft.fft(grav_est.x.values)\n",
    "Grav_est=fft.fftshift(Grav_est)\n",
    "\n",
    "Accel_est=fft.fft(accel_est.x.values)\n",
    "Accel_est=fft.fftshift(Accel_est)\n",
    "\n",
    "pl.figure(figsize=(12,5))\n",
    "ax1=pl.subplot(131)\n",
    "pl.plot(f_vec,np.abs(Accel_raw))\n",
    "pl.xlim((0,f_vec[-1]))\n",
    "pl.grid()\n",
    "pl.title('FFT of Raw Acceleration')\n",
    "pl.xlabel('Frequency (Hz)')\n",
    "pl.subplot(132,sharex=ax1)\n",
    "pl.plot(f_vec,np.abs(Grav_est))\n",
    "pl.xlim((0,f_vec[-1]))\n",
    "pl.grid()\n",
    "pl.title('FFT of Gravity Estimate')\n",
    "pl.xlabel('Frequency (Hz)')\n",
    "ymax=pl.ylim()[1]\n",
    "pl.subplot(133,sharex=ax1)\n",
    "pl.plot(f_vec,np.abs(Accel_est))\n",
    "pl.xlim((0,f_vec[-1]))\n",
    "pl.grid()\n",
    "pl.title('FFT of Acceleration Estimate')\n",
    "pl.xlabel('Frequency (Hz)')\n",
    "pl.ylim((0,ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, we plot the original raw accelerometer data, along with our gravity estimate and phone acceleration in the time domain (i.e., we're plotting the filtered time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot original and filtered data\n",
    "pl.figure(figsize=(13.5,6))\n",
    "ax1=pl.subplot(131)\n",
    "line1,line2,line3,=pl.plot(accel_raw)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Raw Accelerometer Data')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()\n",
    "y_lim=pl.ylim()\n",
    "\n",
    "ax1=pl.subplot(132)\n",
    "line1,line2,line3,=pl.plot(grav_est)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Gravity Estimate')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()\n",
    "pl.ylim(y_lim)\n",
    "\n",
    "ax1=pl.subplot(133)\n",
    "line1,line2,line3,=pl.plot(accel_est)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Acceleration Estimate')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()\n",
    "pl.ylim(y_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality of Estimates\n",
    "--\n",
    "How good are the estimates of gravity and phone acceleration?  One way to check here is to compare our estimated phone acceleration to the processed phone acceleration recorded by the Iphone, which is the data we originally looked at in our FFT example.  Below, we plot our estimate and the iPhone's estimate of phone acceleration side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(9,7))\n",
    "ax1=pl.subplot(211)\n",
    "line1,line2,line3,=pl.plot(accel_est)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Acceleration Estimate')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.grid()\n",
    "\n",
    "pl.subplot(212,sharex=ax1)\n",
    "line1,line2,line3,=pl.plot(accel)\n",
    "pl.legend([line1,line2,line3],['x','y','z'],loc=0)\n",
    "pl.title('Iphone Estimate of Acceleration')\n",
    "pl.ylabel('Acceleration (g\\'s)')\n",
    "pl.xlabel('Time (sec)')\n",
    "pl.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest difference to note is that there is an apparent *time shift* between our estimate of the phone acceleration and the iPhone's estimate.  This is not caused by the filtration process (some filters can cause a time delay, but the filters implemented here are *zero phase* and cannot do this) but, rather, is due to the fact that different portions of the iPhone core motion processor report raw acceleration and processed acceleration, and there is sometimes a time shift between when these two quantities get reported out. \n",
    "\n",
    "Other than the time shift, the salient features between our estimate and the iPhone's estimate, which uses the more complicated Kalman Filter that we mentioned at the beginning of this section, are on par.  And from a data scientist's perspective, all of the filtering and plotting operations were able to be performed almost instantaneously.  These filtering tools are, therefore, easy to implement in just a few lines of code and very quick to run experiments with!\n",
    "\n",
    "Time Delay Estimation\n",
    "--\n",
    "\n",
    "As a parting thought, it turns out that the estimate of phone acceleration produced above can be used in conjunction with the iPhone's estimate of phone acceleration to accurately detect the time delay between the two waveforms.  To do so, we use a class of filtering techniques called *cross-correlation* techniques to correlate time-shifted versions of one of the time series against the other.  The time shift where the two time series best align creates a huge \"spike* in correlation compared to other time shifts and is used as an estimate of the time shift between the two waveforms.  In experiments we've performed with similar end-of-trip data, the time estimate produced in this manner is often *very* accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sandbox)",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
